{
      "cells": [
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## 1. Import libraries"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Basic Libraries\n",
                        "import numpy as np\n",
                        "import pandas as pd\n",
                        "import seaborn as sb\n",
                        "import matplotlib.pyplot as plt # we only need pyplot\n",
                        "sb.set_theme() # set the default Seaborn style for graphics"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## 2. Data cleaning"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### Data cleaning on the raw dataset (spotify_songs.csv) and extract to save it as cleaned_dataset.csv"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Import dataset and check basic information\n",
                        "full_dataset = pd.read_csv('datasets/spotify_songs.csv')\n",
                        "print(full_dataset.shape)\n",
                        "# print(full_dataset.dtypes)\n",
                        "# full_dataset.head()\n",
                        "# full_dataset.describe()\n",
                        "full_dataset.info()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From the printed `.info()` above, we can see that some of the song records in the `full_dataset` contain `NA` values in certain variable columns. Hence, we drop those song records from `full_dataset`."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Apply the dropna() function to remove records with missing values\n",
                        "# Then check the information of the cleaned dataset\n",
                        "full_dataset.dropna(inplace=True)\n",
                        "full_dataset.info()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "Our goal is to predict the popularity of the songs using different variables as predictors.\n",
                        "In order to achieve this:\n",
                        "1. Analyse the 'track_popularity' variable\n",
                        "2. Categorize the track_popularity score into 6 different categories."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Extract the track_popularity column and check its distribution\n",
                        "popularity = pd.DataFrame(full_dataset[\"track_popularity\"])\n",
                        "print(popularity.describe())\n",
                        "print(popularity.value_counts())\n",
                        "\n",
                        "f, axes = plt.subplots(3, 1, figsize=(24, 12), sharex=True)\n",
                        "sb.boxplot(data = popularity, orient = \"h\", ax=axes[0])\n",
                        "sb.histplot(data = popularity, kde = True, ax=axes[1])\n",
                        "sb.violinplot(data = popularity, orient = \"h\", ax=axes[2])"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From the plots and `.value_counts()` above, we can see that there are unexpectedly high number of song records with `track_popularity <= 1`. In order to ensure the datas are more normally distributed, we choose to remove those song records from our `full_dataset`."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Remove records whose value of track_popularity is lower than or equal to 1\n",
                        "full_dataset = full_dataset[full_dataset['track_popularity'] > 1]\n",
                        "popularity = full_dataset[\"track_popularity\"]\n",
                        "\n",
                        "# Check the skewness and distribution of the track_popularity column\n",
                        "from scipy.stats import skew\n",
                        "\n",
                        "print(\"Skewness of popularity:\", skew(popularity))\n",
                        "print(popularity.value_counts())\n",
                        "f, axes = plt.subplots(3, 1, figsize=(24, 12), sharex=True)\n",
                        "sb.boxplot(data = popularity, orient = \"h\", ax=axes[0])\n",
                        "sb.histplot(data = popularity, kde = True, ax=axes[1])\n",
                        "sb.violinplot(data = popularity, orient = \"h\", ax=axes[2])"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From the calculated skewness and plots above, we can clearly see that **`track_popularity` is similar to a normal distribution** if we discard the clustering phenomenon at the lower spectrum.\n",
                        "\n",
                        "Thus, we can then divide `track_popularity` into **6 levels** -- `very_low`, `low`, `somewhat_low`, `somewhat_high`, `high`, and `very_high` -- using mean and standard deviation as the parameters to gauge."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Calculate the mean and standard deviation of track_popularity\n",
                        "mean = popularity.mean()\n",
                        "std = popularity.std()\n",
                        "\n",
                        "# Define the level divisions\n",
                        "very_low = mean - 2 * std\n",
                        "low = mean - std\n",
                        "medium = mean\n",
                        "high = mean + std\n",
                        "very_high = mean + 2 * std\n",
                        "\n",
                        "# Create a new column \"popularity_level\" based on the level divisions\n",
                        "full_dataset[\"popularity_level\"] = pd.cut(full_dataset[\"track_popularity\"], bins=[0, very_low, low, medium, high, very_high, float('inf')], labels=[\"very_low\", \"low\", \"somewhat_low\", \"somewhat_high\", \"high\", \"very_high\"])\n",
                        "\n",
                        "# Check the distribution of popularity levels\n",
                        "popularity_level = pd.DataFrame(full_dataset[\"popularity_level\"].value_counts(sort=False), columns=[\"count\"])\n",
                        "popularity_level[\"density\"] = popularity_level[\"count\"] / len(full_dataset)\n",
                        "popularity_level"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We then save the cleaned dataset to a new CSV file named clean_dataset.csv"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "#Save the extracted and cleaned dataset into a separate file named clean_dataset.csv\n",
                        "full_dataset.to_csv('datasets/cleaned_dataset.csv', index=False)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## 3. Data randomization"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "The current sample size is over 30k, and we choose to reduce it to 5k by random sampling method and save the randomized dataset to a new CSV file named random_sampled_dataset.csv"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sampled_dataset = full_dataset.sample(n=5000, random_state=29) # Use a random seed of 29 for reproducibility\n",
                        "sampled_dataset.to_csv('datasets/random_sampled_dataset.csv', index=False)\n",
                        "print(sampled_dataset.shape)\n",
                        "print(sampled_dataset[\"popularity_level\"].value_counts(sort=False) / len(sampled_dataset))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## 4. EDA and Visualisation analysis on random_sampled.csv"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### Out of all variables in the random_sampled.csv file, we have found several numeric as well as categorical variables for analysis"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### EDA and Visualisation analysis on numeric variables"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We first examine the numeric variables and their relationships with track_popularity"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "numeric_columns = [\"track_popularity\", \"danceability\", \"energy\", \"speechiness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\"]\n",
                        "\n",
                        "print(sampled_dataset[numeric_columns].corr())\n",
                        "sb.heatmap(sampled_dataset[numeric_columns].corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
                        "\n",
                        "f, axes = plt.subplots(3, 1, figsize=(24, 24), sharex=True)\n",
                        "sb.boxplot(data = sampled_dataset[numeric_columns].apply(min_max_normalize), orient = \"h\", ax=axes[0])\n",
                        "sb.histplot(data = sampled_dataset[numeric_columns].apply(min_max_normalize), kde = True, ax=axes[1])\n",
                        "sb.violinplot(data = sampled_dataset[numeric_columns].apply(min_max_normalize), orient = \"h\", ax=axes[2])"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From the heatmap, we find 4 variables with the highest correlations with variable track_popularity (Highest correlation is determined by the highest absolute values of different variables with track_popularity)\n",
                        "The 4 variables are: instrumentalness (correlation with track_popularity = -0.16), energy (correlation with track_popularity = -0.12), duration_ms (correlation with track_popularity = -0.10), danceability (correlation with track_popularity = 0.07)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def min_max_normalize(x):\n",
                        "    return (x - x.min()) / (x.max() - x.min()) * 100\n",
                        "\n",
                        "numeric5_columns = [\"track_popularity\", \"instrumentalness\", \"energy\", \"duration_ms\",\"danceability\"]\n",
                        "print(sampled_dataset[numeric5_columns].corr())\n",
                        "sb.heatmap(sampled_dataset[numeric5_columns].corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
                        "\n",
                        "f, axes = plt.subplots(3, 1, figsize=(24, 36), sharex=True)\n",
                        "sb.boxplot(data = sampled_dataset[numeric5_columns].apply(min_max_normalize), orient = \"h\", ax=axes[0])\n",
                        "sb.histplot(data = sampled_dataset[numeric5_columns].apply(min_max_normalize), kde = True, ax=axes[1])\n",
                        "sb.violinplot(data = sampled_dataset[numeric5_columns].apply(min_max_normalize), orient = \"h\", ax=axes[2])"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From various plots shown above, we can easily see that the variable instrumentalness is not a good variable to be used for eda analysis as the graph is severely skewed.\n",
                        "To further prove our point, we use .describe() functions to see the distribution of the variable"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "print(sampled_dataset[[\"instrumentalness\"]].describe())\n",
                        "print(sampled_dataset[[\"instrumentalness\"]].value_counts())"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "The result above shows that there is a total of 1914 counts out of 5000 that have the instrumentalness value of 0. As there is a serious clustering at the low end, we decide to not use this variable for EDA analysis with track_popularity."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def min_max_normalize(x):\n",
                        "    return (x - x.min()) / (x.max() - x.min()) * 100\n",
                        "\n",
                        "numeric4_columns = [ \"track_popularity\", \"energy\", \"duration_ms\", \"danceability\"]\n",
                        "print(sampled_dataset[numeric4_columns].corr())\n",
                        "sb.heatmap(sampled_dataset[numeric4_columns].corr(), vmin = -1, vmax = 1, annot = True, fmt=\".2f\")\n",
                        "\n",
                        "f, axes = plt.subplots(3, 1, figsize=(24, 36), sharex=True)\n",
                        "sb.boxplot(data = sampled_dataset[numeric4_columns].apply(min_max_normalize), orient = \"h\", ax=axes[0])\n",
                        "sb.histplot(data = sampled_dataset[numeric4_columns].apply(min_max_normalize), kde = True, ax=axes[1])\n",
                        "sb.violinplot(data = sampled_dataset[numeric4_columns].apply(min_max_normalize), orient = \"h\", ax=axes[2])"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### EDA and Visualisation analysis on categorical variables"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "We then examine the categorical variables and their relationships with popularity_level."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "categorical_columns = [\"playlist_genre\", \"playlist_subgenre\", \"mode\", \"key\"]\n",
                        "sampled_dataset[categorical_columns] = sampled_dataset[categorical_columns].astype('category')\n",
                        "sampled_dataset[categorical_columns].describe()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# playlist_genre vs popularity_level\n",
                        "f = plt.figure(figsize=(16, 8))\n",
                        "sb.heatmap(sampled_dataset.groupby(['popularity_level', 'playlist_genre']).size().unstack(),\n",
                        "            linewidths=1, annot = True, fmt = 'g', annot_kws={\"size\": 18}, cmap=\"BuGn\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# playlist_subgenre vs popularity_level\n",
                        "f = plt.figure(figsize=(24, 8))\n",
                        "sb.heatmap(sampled_dataset.groupby(['popularity_level', 'playlist_subgenre']).size().unstack(),\n",
                        "            linewidths=1, annot = True, fmt = 'g', annot_kws={\"size\": 18}, cmap=\"BuGn\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# mode vs popularity_level\n",
                        "f = plt.figure(figsize=(4, 8))\n",
                        "sb.heatmap(sampled_dataset.groupby(['popularity_level', 'mode']).size().unstack(),\n",
                        "            linewidths=1, annot = True, fmt = 'g', annot_kws={\"size\": 18}, cmap=\"BuGn\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# key vs popularity_level\n",
                        "f = plt.figure(figsize=(24, 8))\n",
                        "sb.heatmap(sampled_dataset.groupby(['popularity_level', 'key']).size().unstack(),\n",
                        "            linewidths=1, annot = True, fmt = 'g', annot_kws={\"size\": 18}, cmap=\"BuGn\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "From the diagrams above, we can see that out of all 4 categorical values listed above, 2 of them (mode and playlist_subgenre) display some trends that can be used as predictors. Hence, we will use these two categorical variables and fit them into the models subsequently."
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "## 5. Creating Model 1 for prediction of popularity_level"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "sc1015_mini_project",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.11.5"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
